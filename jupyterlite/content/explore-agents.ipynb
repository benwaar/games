{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \ud83d\udd2c Explore AI Agents\n",
    "\n",
    "Educational deep dive - learn how different agents think!\n",
    "\n",
    "---\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import micropip\n",
    "import js\n",
    "\n",
    "# Get current page URL and extract base (handles both localhost and GitHub Pages)\n",
    "current_path = str(js.location.href)\n",
    "# Remove everything after /lab/ to get base URL\n",
    "if '/lab/' in current_path:\n",
    "    base_url = current_path.split('/lab/')[0]\n",
    "else:\n",
    "    base_url = str(js.location.origin)\n",
    "\n",
    "wheel_url = f'{base_url}/pyodide/utala_kaos_9-0.1.1-py3-none-any.whl'\n",
    "\n",
    "print(f\"Installing from: {wheel_url}\")\n",
    "await micropip.install(wheel_url)\n",
    "print(\"\u2713 Game installed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utala.agents.random_agent import RandomAgent\n",
    "from utala.agents.heuristic_agent import HeuristicAgent\n",
    "from utala.agents.monte_carlo_agent import FastMonteCarloAgent, MonteCarloAgent\n",
    "from utala.evaluation.harness import Harness\n",
    "import inspect\n",
    "\n",
    "print(\"\u2713 Imports complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent Architecture\n",
    "\n",
    "All agents implement the same interface:\n",
    "\n",
    "```python\n",
    "class Agent(ABC):\n",
    "    @abstractmethod\n",
    "    def select_action(\n",
    "        self,\n",
    "        state: GameState,\n",
    "        legal_actions: list[int],\n",
    "        player: Player\n",
    "    ) -> int:\n",
    "        \"\"\"Select an action from legal_actions.\"\"\"\n",
    "        pass\n",
    "```\n",
    "\n",
    "Agents **propose** actions, the engine **validates** and **applies** them.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Random Agent\n",
    "\n",
    "**Strategy**: Uniform random selection from legal actions\n",
    "\n",
    "**Strengths**: \n",
    "- Establishes baseline performance\n",
    "- Deterministic with seed (reproducible)\n",
    "- No computation overhead\n",
    "\n",
    "**Weaknesses**:\n",
    "- No strategic thinking\n",
    "- Ignores board state\n",
    "- Baseline for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View Random Agent source\n",
    "print(\"Random Agent select_action method:\")\n",
    "print(\"=\" * 70)\n",
    "print(inspect.getsource(RandomAgent.select_action))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Heuristic Agent\n",
    "\n",
    "**Strategy**: Rule-based strategic decisions\n",
    "\n",
    "### Placement Strategy\n",
    "- **Center prioritization** (1,1) - forms 4 potential lines\n",
    "- **Edge squares** - form 2-3 potential lines\n",
    "- **Corner squares** - form 2 potential lines\n",
    "- **3-in-a-row detection** - complete winning lines\n",
    "- **Blocking** - prevent opponent victories\n",
    "- **Face-down deception** - use cards 2,3,9,10 strategically\n",
    "\n",
    "### Dogfight Strategy\n",
    "- **As underdog**: Attack when power difference \u2264 -2\n",
    "- **As favorite**: Pass and win via Kaos resolution\n",
    "- **Weapon conservation**: Save for critical fights\n",
    "- **Joker awareness**: Consider tie-breaker advantage\n",
    "\n",
    "**Strengths**:\n",
    "- Beats Random consistently (~65% win rate)\n",
    "- Interpretable decisions\n",
    "- Fast execution\n",
    "\n",
    "**Weaknesses**:\n",
    "- Fixed rules, no adaptation\n",
    "- No look-ahead\n",
    "- Vulnerable to specific patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View key Heuristic Agent methods\n",
    "print(\"Heuristic Agent select_action method (first 30 lines):\")\n",
    "print(\"=\" * 70)\n",
    "source = inspect.getsource(HeuristicAgent.select_action)\n",
    "lines = source.split('\\n')[:30]\n",
    "print('\\n'.join(lines))\n",
    "print(\"\\n... (method continues)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Monte Carlo Agent\n",
    "\n",
    "**Strategy**: Simulate future game states to evaluate actions\n",
    "\n",
    "### Algorithm\n",
    "1. For each legal action:\n",
    "   - Clone game state\n",
    "   - Apply candidate action\n",
    "   - Simulate N random rollouts to game end\n",
    "   - Track win rate\n",
    "2. Select action with highest win rate\n",
    "\n",
    "### Variants\n",
    "- **FastMonteCarloAgent**: 10 rollouts (browser-friendly)\n",
    "- **MonteCarloAgent**: 50 rollouts (default)\n",
    "- **UltraStrongMonteCarloAgent**: 100 rollouts (slow but strong)\n",
    "\n",
    "**Strengths**:\n",
    "- Look-ahead capability\n",
    "- Adapts to game state\n",
    "- Beats Random consistently (~79% win rate)\n",
    "- Often beats Heuristic (~60-70% depending on rollouts)\n",
    "\n",
    "**Weaknesses**:\n",
    "- Computationally expensive\n",
    "- Rollout quality depends on baseline policy\n",
    "- No explicit strategic knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View Monte Carlo Agent evaluation method (first 40 lines)\n",
    "print(\"Monte Carlo Agent _evaluate_action method:\")\n",
    "print(\"=\" * 70)\n",
    "source = inspect.getsource(MonteCarloAgent._evaluate_action)\n",
    "lines = source.split('\\n')[:40]\n",
    "print('\\n'.join(lines))\n",
    "print(\"\\n... (method continues)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparative Performance\n",
    "\n",
    "Let's run a quick comparison:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create agents\n",
    "random = RandomAgent(\"Random\", seed=42)\n",
    "heuristic = HeuristicAgent(\"Heuristic\", seed=123)\n",
    "mc_fast = FastMonteCarloAgent(\"MC-Fast\", seed=456)\n",
    "\n",
    "# Run matches\n",
    "harness = Harness(verbose=False)\n",
    "\n",
    "print(\"Running comparative analysis (3 games each)...\\n\")\n",
    "\n",
    "# Heuristic vs Random\n",
    "result1 = harness.run_match(heuristic, random, num_games=3, starting_seed=5000)\n",
    "print(f\"Heuristic vs Random: {result1.player_one_wins} - {result1.player_two_wins} (draws: {result1.draws})\")\n",
    "\n",
    "# Monte Carlo vs Random  \n",
    "result2 = harness.run_match(mc_fast, random, num_games=3, starting_seed=5100)\n",
    "print(f\"MC-Fast vs Random: {result2.player_one_wins} - {result2.player_two_wins} (draws: {result2.draws})\")\n",
    "\n",
    "# Monte Carlo vs Heuristic\n",
    "result3 = harness.run_match(mc_fast, heuristic, num_games=3, starting_seed=5200)\n",
    "print(f\"MC-Fast vs Heuristic: {result3.player_one_wins} - {result3.player_two_wins} (draws: {result3.draws})\")\n",
    "\n",
    "print(\"\\n\u2713 Analysis complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Insights\n",
    "\n",
    "### Phase 1 Design Principles\n",
    "\n",
    "1. **Determinism**: All randomness lives in the engine, agents are deterministic\n",
    "2. **Fixed Action Space**: 86 actions total (81 placements + 4 weapons + 1 pass)\n",
    "3. **Action Masking**: Illegal actions masked, never removed\n",
    "4. **State Immutability**: Agents receive read-only state copies\n",
    "5. **No External Dependencies**: Pure Python, standard library only\n",
    "\n",
    "### Why No ML Frameworks?\n",
    "\n",
    "Phase 1 deliberately avoids ML frameworks to:\n",
    "- Establish **interpretable baselines**\n",
    "- Verify game has **skill gradient** (not pure luck)\n",
    "- Understand **what makes strategies strong**\n",
    "- Create **measurement infrastructure**\n",
    "\n",
    "Phase 2 will introduce learning methods only after baseline verification.\n",
    "\n",
    "---\n",
    "\n",
    "## Experiment Ideas\n",
    "\n",
    "Want to experiment? Try:\n",
    "\n",
    "1. **Modify rollout counts**: Create agents with different N values\n",
    "2. **Hybrid strategies**: Combine heuristics with Monte Carlo\n",
    "3. **Analyze specific games**: Set seeds and examine decision points\n",
    "4. **Measure computation time**: Profile agent performance\n",
    "\n",
    "All source code is accessible - feel free to inspect and modify!\n",
    "\n",
    "---\n",
    "\n",
    "[Return to home](index.ipynb) | [Play vs AI](play-vs-ai.ipynb) | [Watch Tournament](watch-tournament.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}